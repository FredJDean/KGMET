{
    "model_name": "gpt2-xl",
    "layers": [13, 14, 15, 16, 17],
    "clamp_norm_factor": 0.75,
    "layer_selection": "all",
    "fact_token": "subject_last",
    "v_num_grad_steps": 30,
    "v_lr": 5e-1,
    "v_loss_layer": 47,
    "v_weight_decay": 0.5,
    "kl_factor": 0.0625,
    "mom2_adjustment": true,
    "mom2_update_weight": 20000,
    "rewrite_module_tmp": "transformer.h.{}.mlp.c_proj",
    "layer_module_tmp": "transformer.h.{}",
    "mlp_module_tmp": "transformer.h.{}.mlp.c_proj",
    "attn_module_tmp": "transformer.h.{}.attn.c_proj",
    "ln_f_module": "transformer.ln_f",
    "lm_head_module": "lm_head",
    "mom2_dataset": "wikipedia",
    "mom2_n_samples": 100000,
    "mom2_dtype": "float32",
    "nullspace_threshold":2e-2,
    "L2":20,
    "subgraph_size": 35,
    "gnn_fact_token_strategy": "avg",
    "gnn_weight_decay": 5e-1,
    "gnn_dim_factor": 1,
    "gnn_attn_drop": 0.2,
    "gnn_feat_drop": 0.15,
    "get_repr_layer": 15,
    "gnn_loss_layer": 47,
    "gnn_lr": 1e-1,
    "factor_g": 10,
    "layer_mlp_input": "model.layers.{}.mlp.down_proj"
}
